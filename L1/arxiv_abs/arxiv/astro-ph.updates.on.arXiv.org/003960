We test whether advanced galaxy models and analysis techniques of simulations can alleviate the
Too Big To Fail problem (TBTF) for late-type galaxies, which states that isolated dwarf galaxy kinematics
imply that dwarfs live in lower-mass halos than is expected in a {\Lambda}CDM universe. Furthermore,
we want to explain this apparent tension between theory and observations. To do this, we use the MoRIA
suite of dwarf galaxy simulations to investigate whether observational effects are involved in
TBTF for late-type field dwarf galaxies. To this end, we create synthetic radio data cubes of the
simulated MoRIA galaxies and analyse their HI kinematics as if they were real, observed galaxies.
We find that for low-mass galaxies, the circular velocity profile inferred from the HI kinematics
often underestimates the true circular velocity profile, as derived directly from the enclosed
mass. Fitting the HI kinematics of MoRIA dwarfs with a theoretical halo profile results in a systematic
underestimate of the mass of their host halos. We attribute this effect to the fact that the interstellar
medium of a low-mass late-type dwarf is continuously stirred by supernova explosions into a vertically
puffed-up, turbulent state to the extent that the rotation velocity of the gas is simply no longer
a good tracer of the underlying gravitational force field. If this holds true for real dwarf galaxies
as well, it implies that they inhabit more massive dark matter halos than would be inferred from their
kinematics, solving TBTF for late-type field dwarf galaxies. 