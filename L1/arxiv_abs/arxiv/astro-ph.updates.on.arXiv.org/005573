In this paper, we propose a new method to obtain the depletion factor $\gamma (z)$, the ratio by which
the measured baryon fraction in galaxy clusters is depleted with respect to the universal mean.
We use exclusively galaxy cluster data, namely, X-ray gas mass fraction ($f_{gas}$) and angular
diameter distance measurements from Sunyaev-Zel'dovich effect plus X-ray observations. The
galaxy clusters are the same in both data set and the non-isothermal spherical double $\beta$-model
was used to describe their electron density and temperature profiles. In order to compare our results
with those from recent cosmological hydrodynamical simulations, we supose a possible time evolution
for $\gamma(z)$, such as, $\gamma(z) = \gamma_0(1 + \gamma_1z)$. As main conclusions we found that:
the $\gamma_0$ value is in full agreement with the simulations, but the $\gamma_1$ value indicates
a time evolution for the baryon depletion factor, which is not predicted by current simulations.
However, we also put constraints on the gas depletion factor by using the gas mass fraction measurements
and angular diameter distances obtained from the flat $\Lambda$CDM model constrained by the current
cosmic microwave background radiation observations. No significant time evolution for $\gamma(z)$
was found. Then, if a constant depletion factor is an inherent characteristic of gas mass fraction
measurements, our results show that the non-isothermal double $\beta$-model does not affect the
quality of these measurements, unlike what occurs with the angular diameter distance measurements
obtained from the SZE/X-ray technique. 