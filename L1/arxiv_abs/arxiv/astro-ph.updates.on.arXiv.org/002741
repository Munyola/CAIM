The estimation and utilization of photometric redshift probability density functions (photo-$z$
PDFs) has become increasingly important over the last few years and currently there exist a wide
variety of algorithms to compute photo-$z$'s, each with their own strengths and weaknesses. In
this paper, we present a novel and efficient Bayesian framework that combines the results from different
photo-$z$ techniques into a more powerful and robust estimate by maximizing the information from
the photometric data. To demonstrate this we use a supervised machine learning technique based
on random forest, an unsupervised method based on self-organizing maps, and a standard template
fitting method but can be easily extend to other existing techniques. We use data from the DEEP2 and
the SDSS surveys to explore different methods for combining the predictions from these techniques.
By using different performance metrics, we demonstrate that we can improve the accuracy of our final
photo-$z$ estimate over the best input technique, that the fraction of outliers is reduced, and
that the identification of outliers is significantly improved when we apply a Na\"{\i}ve Bayes
Classifier to this combined information. Our more robust and accurate photo-$z$ PDFs will allow
even more precise cosmological constraints to be made by using current and future photometric surveys.
These improvements are crucial as we move to analyze photometric data that push to or even past the
limits of the available training data, which will be the case with the Large Synoptic Survey Telescope.
