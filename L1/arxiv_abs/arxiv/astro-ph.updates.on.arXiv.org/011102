With a statistical detection of the 21 cm signal fluctuations from the Epoch of Reionization (EoR)
expected in the next few years, there is an interest in developing robust and precise techniques
to constrain the underlying astrophysical parameters. Bayesian inference with Markov Chain Monte
Carlo, or different types of supervised learning for backward modelling (from signal to parameters)
are examples of such techniques. They usually require many instances of forward modelling (from
parameters to signal) in sampling the parameters space, either when performing the steps of the
Markov Chain or when building a training sample for supervised learning. As forward modelling can
be costly (if performed with numerical simulations for example), we should attempt to perform an
optimal sampling according to some principle. With this goal in mind, we present an approach based
on defining a metric on the space of observables, induced by the manner through which the modelling
creates a mapping from the parameter space onto the space of observables. This metric bears a close
connection to Jeffreys' prior from information theory. It is used to generate a homogeneous and
isotropic sampling of the signal space with two different methods. We show that when the resulting
optimized samplings, created with 21cmFAST, are used to train a neural network we obtain a modest
reduction of the error on parameter reconstruction of ~10% (compared to a na\"ive sampling of the
same size). Excluding the borders of the parameter space region, the improvement is more substantial,
on the order of 30-40%. 