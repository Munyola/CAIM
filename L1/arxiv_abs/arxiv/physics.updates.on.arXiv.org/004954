Breast ultrasound (US) is an effective imaging modality for breast cancer detection and diagnosis.
US computer-aided diagnosis (CAD) systems have been developed for decades and have employed either
conventional hand-crafted features or modern automatic deep-learned features, the former relying
on clinical experience and the latter demanding large datasets. In this paper, we have developed
a novel BIRADS-SDL network that integrates clinically-approved breast lesion characteristics
(BIRADS features) into semi-supervised deep learning (SDL) to achieve accurate diagnoses with
a small training dataset. Breast US images are converted to BIRADS-oriented feature maps (BFMs)
using a distance-transformation coupled with a Gaussian filter. Then, the converted BFMs are used
as the input of an SDL network, which performs unsupervised stacked convolutional auto-encoder
(SCAE) image reconstruction guided by lesion classification. We trained the BIRADS-SDL network
with an alternative learning strategy by balancing reconstruction error and classification label
prediction error. We compared the performance of the BIRADS-SDL network with conventional SCAE
and SDL methods that use the original images as inputs, as well as with an SCAE that use BFMs as inputs.
Experimental results on two breast US datasets show that BIRADS-SDL ranked the best among the four
networks, with classification accuracy around 92.00% and 83.90% on two datasets. These findings
indicate that BIRADS-SDL could be promising for effective breast US lesion CAD using small datasets.
