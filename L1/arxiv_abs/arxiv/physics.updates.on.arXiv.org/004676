The analog signals generated in the read-out electronics of radiation detectors are shaped prior
to the digitization in order to improve the signal to noise ratio (SNR). The real amplitude of the
analog signal is then obtained using digital filters, which provides information about the energy
deposited in the detector. The classical digital filters have a good performance in ideal situations
with Gaussian electronic noise and no pulse shape distortion. However, high-energy particle colliders,
such as the Large Hadron Collider (LHC) at CERN, can produce multiple simultaneous radiation events,
which produce signal pileup. The performance of classical digital filters deteriorates in these
conditions since the signal pulse shape gets distorted. In addition, this type of experiments produces
a high rate of collisions, which requires high throughput data acquisitions systems. In order to
cope with these harsh requirements, new read-out electronics systems are based on high-performance
FPGAs, which permit the utilization of more advanced real-time signal reconstruction algorithms.
In this paper, a deep learning method is proposed for real-time signal reconstruction in high pileup
radiation detectors. The performance of the new method has been studied using simulated data and
the results are compared with a classical FIR filter method. In particular, the signals and FIR filter
used in the ATLAS Tile Calorimeter are used as benchmark. The implementation, resources usage and
performance of the proposed Neural Network algorithm in FPGA are also presented. 