The ability to integrate information into a unified coherent whole is a fundamental capacity of
many biological and cognitive systems. Integrated Information Theory (IIT) provides a mathematical
approach to quantify the level of integration in a system. Nevertheless, it is not yet well understood
how integration scales up with the size of a system or with different temporal scales of activity,
nor how a system maintains its integration as its interacts with its environment. We argue that modelling
and understanding how measures of information integration operate in these scenarios is fundamental
to adequately capture integration in systems such as the brain. We propose a simplified and modified
version of integrated information {\phi} in order to explore these questions. Using mean field
approximations, we measure {\phi} in a kinetic Ising models of infinite size. We find that information
integration diverges in some cases when the system is near critical points in continuous phase transitions.
Moreover, we find that we can delimit the boundary of a system with respect to its environment by comparing
the divergent integrative tendencies of system and system-environment processes respectively.
Finally, we model a system that maintains integrated information when interacting with a range
of different environments by generating a critical surface spanning a parametric region of the
environment. We conclude by discussing how thinking about integrated information in the thermodynamic
limit opens fruitful research avenues for studying the organization of biological and cognitive
systems. 