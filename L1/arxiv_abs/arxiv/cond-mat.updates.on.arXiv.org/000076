We study the effects of time-dependent substrate/film temperature in the deposition of a mesoscopically
thick film using a statistical model that accounts for diffusion of adsorbed atoms with coefficients
dependent on an activation energy and temperature. For simplicity, a model where only adatoms without
lateral neighbors can move is studied by computer simulation, with deposition of typically ${10}^4$
atomic layers and temperature changes up to $30 K$, near or below the room temperature range. Linearly
varying and exponentially converging temperature cases are considered. If the temperature decreases
during the growth, the global roughness slowly increases at short times, but may show a rapid growth
with exponent $\beta >1/2$ after $\sim {10}^3$ monolayers. In the exponentially converging
case, the local roughness shows evidence of anomalous scaling, with a large range of the anomalous
exponent, and in the linearly decreasing case the local roughness may increase faster than a power
law. If the temperature increases during the growth, a non-monotonic evolution of the global roughness
may be observed, with a maximum in the linearly increasing case and a sequence of maximum and minimum
in the case of exponential convergence to a final temperature. This is explained by the competition
of kinetic roughening and the smoothing effect of increasing diffusion coefficients. If some of
these features are observed in experiments, our results suggest to investigate the possibility
of time varying temperature before relating them to more complex physico-chemical mechanisms.
