Reservoir Computing (RC) is a powerful computational paradigm that allows high versatility with
cheap learning. While other artificial intelligence approaches need exhaustive resources to
specify their inner workings, RC is based on a reservoir with highly non-linear dynamics that does
not require a fine tuning of its parts. These dynamics project input signals into high-dimensional
spaces, where training linear readouts to extract input features is vastly simplified. Thus, inexpensive
learning provides very powerful tools for decision making, controlling dynamical systems, classification,
etc. RC also facilitates solving multiple tasks in parallel, resulting in a high throughput. Existing
literature focuses on applications in artificial intelligence and neuroscience. We review this
literature from an evolutionary perspective. RC's versatility make it a great candidate to solve
outstanding problems in biology, which raises relevant questions: Is RC as abundant in Nature as
its advantages should imply? Has it evolved? Once evolved, can it be easily sustained? Under what
circumstances? (In other words, is RC an evolutionarily stable computing paradigm?) To tackle
these issues we introduce a conceptual morphospace that would map computational selective pressures
that could select for or against RC and other computing paradigms. This guides a speculative discussion
about the questions above and allows us to propose a solid research line that brings together computation
and evolution with RC as a working bench. 