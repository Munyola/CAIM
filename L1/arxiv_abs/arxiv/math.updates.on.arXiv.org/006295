We consider the classic supervised learning problem, where a continuous non-negative random label
$Y$ (i.e. a random duration) is to be predicted based upon observing a random vector $X$ valued in
$\mathbb{R}^d$ with $d\geq 1$ by means of a regression rule with minimum least square error. In various
applications, ranging from industrial quality control to public health through credit risk analysis
for instance, training observations can be right censored, meaning that, rather than on independent
copies of $(X,Y)$, statistical learning relies on a collection of $n\geq 1$ independent realizations
of the triplet $(X, \; \min\{Y,\; C\},\; \delta)$, where $C$ is a nonnegative r.v. with unknown distribution,
modeling censorship and $\delta=\mathbb{I}\{Y\leq C\}$ indicates whether the duration is right
censored or not. As ignoring censorship in the risk computation may clearly lead to a severe underestimation
of the target duration and jeopardize prediction, we propose to consider a plug-in estimate of the
true risk based on a Kaplan-Meier estimator of the conditional survival function of the censorship
$C$ given $X$, referred to as Kaplan-Meier risk, in order to perform empirical risk minimization.
It is established, under mild conditions, that the learning rate of minimizers of this biased/weighted
empirical risk functional is of order $O_{\mathbb{P}}(\sqrt{\log(n)/n})$ when ignoring model
bias issues inherent to plug-in estimation, as can be attained in absence of censorship. Beyond
theoretical results, numerical experiments are presented in order to illustrate the relevance
of the approach developed. 