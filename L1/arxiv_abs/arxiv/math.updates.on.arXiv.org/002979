For sequential stochastic control problems with standard Borel measurement and control action
spaces, we introduce a very general dynamic programming formulation, establish its well-posedness,
and provide new existence results for optimal policies. Our dynamic program builds in part on Witsenhausen's
standard form, but with a different formulation for the state, action, and transition dynamics.
Using recent results on measurability properties of strategic measures in decentralized control,
we obtain a controlled Markov model with standard Borel state and state dependent action sets. This
allows for a well-posed formulation for the controlled Markov model for a general class of sequential
decentralized stochastic control in that it leads to well-defined dynamic programming recursions
through universal measurability properties of the value functions for each time stage. Through
this formulation, new existence results are obtained for optimal team policies in decentralized
stochastic control. These state that for a static team with independent measurements, it suffices
for the cost function to be continuous in the actions for the existence of an optimal policy under
mild compactness conditions. These also apply to dynamic teams which admit static reductions with
independent measurements through a change of measure transformation. We show through a counterexample
that weaker conditions may not lead to existence of an optimal team policy. In particular, the paper
presents existence results which complement and generalize those previously reported. 