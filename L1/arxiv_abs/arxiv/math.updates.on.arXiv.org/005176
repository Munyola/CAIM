We consider the tuning parameter selection rules for nuclear norm regularized multivariate linear
regression (NMLR) in high-dimensional setting. High-dimensional multivariate linear regression
is widely used in statistics and machine learning, and regularization technique is commonly applied
to deal with the special structures in high-dimensional data. As we know, how to select the tuning
parameter is an essential issue for regularization approach and it directly affects the model estimation
performance. To the best of our knowledge, there are no rules about the tuning parameter selection
for NMLR from the point of view of optimization. In order to establish such rules, we study the duality
theory of NMLR. Then, we claim the choice of tuning parameter for NMLR is based on the sample data and
the solution of NMLR dual problem, which is a projection on a nonempty, closed and convex set. Moreover,
based on the (firm) nonexpansiveness and the idempotence of the projection operator, we build four
tuning parameter selection rules PSR, PSRi, PSRfn and PSR+. Furthermore, we give a sequence of tuning
parameters and the corresponding intervals for every rule, which states that the rank of the estimation
coefficient matrix is no more than a fixed number for the tuning parameter in the given interval.
The relationships between these rules are also discussed and PSR+ is the most efficient one to select
the tuning parameter. Finally, the numerical results are reported on simulation and real data,
which show that these four tuning parameter selection rules are valuable. 