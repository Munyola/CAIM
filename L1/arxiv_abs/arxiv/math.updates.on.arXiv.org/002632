In this paper we consider the cubic regularization (CR) method for minimizing a twice continuously
differentiable function. While the CR method is widely recognized as a globally convergent variant
of Newton's method with superior iteration complexity, existing results on its local quadratic
convergence require a stringent non-degeneracy condition. We prove that under a local error bound
(EB) condition, which is much weaker a requirement than the existing non-degeneracy condition,
the sequence of iterates generated by the CR method converges at least Q-quadratically to a second-order
critical point. This indicates that adding a cubic regularization not only equips Newton's method
with remarkable global convergence properties but also enables it to converge quadratically even
in the presence of degenerate solutions. As a byproduct, we show that without assuming convexity,
the proposed EB condition is equivalent to a quadratic growth condition, which could be of independent
interest. To demonstrate the usefulness and relevance of our convergence analysis, we focus on
two concrete nonconvex optimization problems that arise in phase retrieval and low-rank matrix
recovery, respectively, and prove that with overwhelming probability, the sequence of iterates
generated by the CR method for solving these two problems converges at least Q-quadratically to
a global minimizer. We also present numerical results of the CR method when applied to solve these
two problems to support and complement our theoretical development. 