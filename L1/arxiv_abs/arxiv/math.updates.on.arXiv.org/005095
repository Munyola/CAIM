The posterior matching scheme, for feedback encoding of a message point lying on the unit interval
over memoryless channels, maximizes mutual information for an arbitrary number of channel uses.
However, it in general does not always achieve any positive rate; so far, elaborate analyses have
been required to show that it achieves any positive rate below capacity. More recent efforts have
introduced a random "dither" shared by the encoder and decoder to the problem formulation, to simplify
analyses and guarantee that the randomized scheme achieves any rate below capacity. Motivated
by applications (e.g. human-computer interfaces) where (a) common randomness shared by the encoder
and decoder may not be feasible and (b) the message point lies in a higher dimensional space, we focus
here on the original formulation without common randomness, and use optimal transport theory to
generalize the scheme for a message point in a higher dimensional space. By defining a stricter,
almost sure, notion of message decoding, we use classical probabilistic techniques (e.g. change
of measure and martingale convergence) to establish succinct necessary and sufficient conditions
on when the message point can be recovered from infinite observations: Birkhoff ergodicity of a
random process sequentially generated by the encoder. We also show a surprising "all or nothing"
result: the same ergodicity condition is necessary and sufficient to achieve any rate below capacity.
We provide applications of this message point framework in human-computer interfaces and multi-antenna
communications. 