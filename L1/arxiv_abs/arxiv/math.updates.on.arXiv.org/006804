One of the hallmarks of real networks is their ability to perform increasingly complex tasks as their
topology evolves. To explain this, it has been observed that as a network grows certain subsets of
the network begin to specialize the function(s) they perform. A recent model of network growth based
on this notion of specialization has been able to reproduce some of the most well-known topological
features found in real-world networks including right-skewed degree distributions, the small
world property, modular as well as hierarchical topology, etc. Here we describe how specialization
under this model also effects the spectral properties of a network. This allows us to give conditions
under which a network is able to maintain its dynamics as its topology evolves. Specifically, we
show that if a network is intrinsically stable, which is a stronger version of the standard notion
of global stability, then the network maintains this type of dynamics as the network evolves. This
is one of the first steps toward unifying the rigorous study of the two types of dynamics exhibited
by networks. These are the \emph{dynamics of} a network, which is the study of the topological evolution
of the network's structure, modeled here by the process of network specialization, and the \emph{dynamics
on} a network, which is the changing state of the network elements, where the type of dynamics we consider
is global stability. The main examples we apply our results to are recurrent neural networks, which
are the basis of certain types of machine learning algorithms. 