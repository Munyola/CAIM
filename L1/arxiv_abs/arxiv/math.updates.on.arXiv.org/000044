Automatic numerical algorithms are widely used in practice. An algorithm that is automatic attempts
to provide an approximate solution that differs from the true solution by no more than a user-specified
error tolerance, $\varepsilon$. Furthermore, the computational effort required is typically
determined adaptively by the algorithm based on function data, e.g., function values. Ideally,
the computational cost should match the difficulty of the problem. Unfortunately, most automatic
algorithms lack \emph{rigorous guarantees}, i.e., sufficient conditions on the input function
that ensure the success of the algorithm. This article establishes a framework for automatic, adaptive
algorithms that do have rigorous guarantees. Sufficient conditions for success and upper bounds
on the computational cost are provided in Theorems 1 and 2. Lower bounds on the complexity of the problem
are given in Theorem 4 and conditions are given under which the proposed algorithms attain those
lower bounds in Corollary 1. These general theorems are illustrated with automatic algorithms
for univariate numerical integration and function recovery. Both algorithms use linear splines
to approximate the input function. The key idea behind these automatic algorithms is that the error
analysis should be done for \emph{cones} of input functions rather than balls. The existing literature
contains certain negative results about the usefulness and reliability of automatic algorithms.
The theory presented does not share the assumptions on which those negative results are based, and
so they are irrelevant. 