It is well known that stability is the most fundamental nature with regard to a control system, in
view of this, the stabilization becomes an inevitable control problem. This article mainly discusses
the optimal control and stabilization problem for discrete-time systems involving Markov jump
and multiplicative noise. The state and control weighting matrices in the cost function are allowed
to be indefinite. By solving the forward-backward stochastic difference equations with Markov
jump (FBSDEs-MJ) derived from the maximum principle, we conclude that the necessary and sufficient
conditions of the solvability of indefinite optimal control problem in finite-horizon, whose
method is different from most previous works [13], etc. Furthermore, necessary and sufficient
conditions that stabilize the Markov jump discrete- time systems in the mean square sense with indefinite
weighting matrices in the cost are first developed under the basic assumption of exactly observable,
which is different from the previous works [12], [14] where an additional assumption of stabilization
of systems is made. The key points of this article can be summed up as that an analytic solution to FBSDEs-
MJ which makes the optimal controller to be explicitly expressed and the method of trans- formation,
i.e., the stabilization problem of indefinite case is boiled down to a definite one whose stabilization
is expressed by defining Lyapunov function via the optimal cost subject to a new algebraic Riccati
equation involving Markov jump (NGARE-MJ). 