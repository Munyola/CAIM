An unknown $m$ by $n$ matrix $X_0$ is to be estimated from noisy measurements $Y = X_0 + Z$, where the
noise matrix $Z$ has i.i.d Gaussian entries. A popular matrix denoising scheme solves the nuclear
norm penalization problem $\min_X || Y - X ||_F^2/2 + \lambda ||X||_* $, where $ ||X||_*$ denotes
the nuclear norm (sum of singular values). This is the analog, for matrices, of $\ell_1$ penalization
in the vector case. It has been empirically observed that, if $X_0$ has low rank, it may be recovered
quite accurately from the noisy measurement $Y$. In a proportional growth framework where the rank
$r_n$, number of rows $m_n$ and number of columns $n$ all tend to $\infty$ proportionally to each
other ($ r_n/m_n -> \rho$, $m_n/n ->\beta$), we evaluate the asymptotic minimax MSE $M(\rho,
\beta) = \lim_{m_n,n \goto \infty} \inf_\lambda \sup_{rank(X) \leq r_n} MSE(X,\hat{X}_\lambda)$
Our formulas involve incomplete moments of the quarter- and semi-circle laws ($\beta = 1$, square
case) and the Mar\v{c}enko-Pastur law ($\beta < 1$, non square case). We also show that any least-favorable
matrix $X_0$ has norm "at infinity". The nuclear norm penalization problem is solved by applying
soft thresholding to the singular values of $Y$. We also derive the minimax threshold, namely the
value $\lambda^*(\rho)$ which is the optimal place to threshold the singular values. All these
results are obtained for general (non square, non symmetric) real matrices. Comparable results
are obtained for square symmetric nonnegative- definite matrices. 