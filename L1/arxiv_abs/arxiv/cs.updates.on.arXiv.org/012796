Graphs are ubiquitous real-world data structures, and generative models that can approximate
distributions over graphs and derive samples from it have significant importance. There are several
known challenges in graph generation tasks, and scalability handling large graphs and datasets
is one of the most important for applications in a wide range of real-world domains. Although an increasing
number of graph generative models have been proposed in the field of machine learning that have demonstrated
impressive results in several tasks, scalability is still an unresolved problem owing to the complex
generation process or difficulty in training parallelization. In this work, we first define scalability
from three different perspectives: number of nodes, data, and node/edge labels, and then we propose
GRAM, a generative model for real-world graphs that is scalable in all the three contexts, especially
on training. We aim to achieve scalability by employing a novel graph attention mechanism, formulating
the likelihood of graphs in a simple and general manner and utilizing the properties of real-world
graphs such as community structure and sparseness of edges. Furthermore, we construct a non-domain-specific
evaluation metric in node/edge-labeled graph generation tasks that combine a graph kernel and
Maximum Mean Discrepancy. Our experiments on real-world graph datasets showed that our models
can scale up to large graphs and datasets that baseline models had difficulty handling, and demonstrated
results that were competitive with or superior than the baseline methods. 