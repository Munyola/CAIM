Data from motion sensors such as accelerometers and gyroscopes embedded in our devices can reveal
secondary undesired, private information about our activities. This information can be used for
malicious purposes such as user identification by application developers. To address this problem,
we propose a data transformation mechanism that enables a device to share data for specific applications
(e.g.~monitoring their daily activities) without revealing private user information (e.g.~
user identity). We formulate this anonymization process based on an information theoretic approach
and propose a new multi-objective loss function for training convolutional auto-encoders~(CAEs)
to provide a practical approximation to our anonymization problem. This effective loss function
forces the transformed data to minimize the information about the user's identity, as well as the
data distortion to preserve application-specific utility. Our training process regulates the
encoder to disregard user-identifiable patterns and tunes the decoder to shape the final output
independently of users in the training set. Then, a trained CAE can be deployed on a user's mobile
device to anonymize sensor data before sharing with an app, even for users who are not included in
the training dataset. The results, on a dataset of 24 users for activity recognition, show a promising
trade-off on transformed data between utility and privacy, with an accuracy for activity recognition
over 92%, while reducing the chance of identifying a user to less than 7%. 