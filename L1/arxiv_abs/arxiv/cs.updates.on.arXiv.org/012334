An image is not just a collection of objects, but rather a graph where each object is related to other
objects through spatial and semantic relations. Using relational reasoning modules, such as the
non-local module \cite{wang2017non}, can therefore improve object detection. Current schemes
apply such dedicated modules either to a specific layer of the bottom-up stream, or between already-detected
objects. We show that the relational process can be better modeled in a coarse-to-fine manner and
present a novel framework, applying a non-local module sequentially to increasing resolution
feature maps along the top-down stream. In this way, information can naturally passed from larger
objects to smaller related ones. Applying the module to fine feature maps further allows the information
to pass between the small objects themselves, exploiting repetitions of instances of the same class.
In practice, due to the expensive memory utilization of the non-local module, it is infeasible to
apply the module as currently used to high-resolution feature maps. We redesigned the non local
module, improved it in terms of memory and number of operations, allowing it to be placed anywhere
along the network. We further incorporated relative spatial information into the module, in a manner
that can be incorporated into our efficient implementation. We show the effectiveness of our scheme
by improving the results of detecting small objects on COCO by 1-2 AP points over Faster and Mask RCNN
and by 1 AP over using non-local module on the bottom-up stream. 