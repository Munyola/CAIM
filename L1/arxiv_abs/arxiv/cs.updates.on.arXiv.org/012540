Mouse dynamics is a potential means of authenticating users. Typically, the authentication process
is based on classical machine learning techniques, but recently, deep learning techniques have
been introduced for this purpose. Although prior research has demonstrated how machine learning
and deep learning algorithms can be bypassed by carefully crafted adversarial samples, there has
been very little research performed on the topic of behavioural biometrics in the adversarial domain.
In an attempt to address this gap, we built a set of attacks, which are applications of several generative
approaches, to construct adversarial mouse trajectories that bypass authentication models.
These generated mouse sequences will serve as the adversarial samples in the context of our experiments.
We also present an analysis of the attack approaches we explored, explaining their limitations.
In contrast to previous work, we consider the attacks in a more realistic and challenging setting
in which an attacker has access to recorded user data but does not have access to the authentication
model or its outputs. We explore three different attack strategies: 1) statistics-based, 2) imitation-based,
and 3) surrogate-based; we show that they are able to evade the functionality of the authentication
models, thereby impacting their robustness adversely. We show that imitation-based attacks often
perform better than surrogate-based attacks, unless, however, the attacker can guess the architecture
of the authentication model. In such cases, we propose a potential detection mechanism against
surrogate-based attacks. 