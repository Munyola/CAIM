The remarkable success of machine learning, especially deep learning, has produced a variety of
cloud-based services for mobile users. Such services require an end user to send data to the service
provider, which presents a serious challenge to end-user privacy. To address this concern, prior
works either add noise to the data or send features extracted from the raw data. They struggle to balance
between the utility and privacy because added noise reduces utility and raw data can be reconstructed
from extracted features. This work represents a methodical departure from prior works: we balance
between a measure of privacy and another of utility by leveraging adversarial learning to find a
sweeter tradeoff. We design an encoder that optimizes against the reconstruction error (a measure
of privacy), adversarially by a Decoder, and the inference accuracy (a measure of utility) by a Classifier.
The result is RAN, a novel deep model with a new training algorithm that automatically extracts features
for classification that are both private and useful. It turns out that adversarially forcing the
extracted features to only conveys the intended information required by classification leads
to an implicit regularization leading to better classification accuracy than the original model
which completely ignores privacy. Thus, we achieve better privacy with better utility, a surprising
possibility in machine learning! We conducted extensive experiments on five popular datasets
over four training schemes, and demonstrate the superiority of RAN compared with existing alternatives.
