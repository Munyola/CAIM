Existing attention mechanisms, are mostly item-based in that a model is trained to attend to individual
items in a collection (the memory) where each item has a predefined, fixed granularity, e.g., a character
or a word. Intuitively, an area in the memory consisting of multiple items can be worth attending
to as a whole. We propose area attention: a way to attend to an area of the memory, where each area contains
a group of items that are either spatially adjacent when the memory has a 2-dimensional structure,
such as images, or temporally adjacent for 1-dimensional memory, such as natural language sentences.
Importantly, the size of an area, i.e., the number of items in an area or the level of aggregation,
is dynamically determined via learning, which can vary depending on the learned coherence of the
adjacent items. By giving the model the option to attend to an area of items, instead of only individual
items, a model can attend to information with varying granularity. Area attention can work along
multi-head attention for attending to multiple areas in the memory. We evaluate area attention
on two tasks: neural machine translation (both character and token-level) and image captioning,
and improve upon strong (state-of-the-art) baselines in all the cases. These improvements are
obtainable with a basic form of area attention that is parameter free. In addition to proposing the
novel concept of area attention, we contribute an efficient way for computing it by leveraging the
technique of summed area tables. 