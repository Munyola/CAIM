Segmentation of nasopharyngeal carcinoma (NPC) from Magnetic Resonance Images (MRI) is a crucial
step in NPC radiotherapy. However, manually segmenting of NPC is a time-consuming and labor-intensive
task. Additionally, single-modality MRI generally cannot provide enough information for the
accurate delineation of NPC. Therefore, a multi-modality MRI fusion network (MMFNet) based on
three modalities of MRI (T1, T2 and contrast-enhanced T1) is proposed to complete accurate segmentation
of NPC. In the MMFNet, the backbone is designed as a multi-encoder-based network, consisting of
several modality-specific encoders and one single decoder. It can be used to well learn both low-level
and high-level features used implicitly for NPC segmentation in each modality of MRI. A fusion block
is proposed in the MMFNet to effectively fuse low-level features from multi-modality MRI. It firstly
recalibrates features captured from multi-modality MRI, which will highlight informative features
and regions of interest. Then, a residual fusion block is utilized to fuse weighted features before
merging them with features from decoder to keep balance between high-level and low-level features.
Moreover, a training strategy named self-transfer is proposed to initialize encoders for multi-encoder-based
network. It can stimulate encoders to make full mining of modality-specific MRI. The proposed method
can effectively make use of information in multi-modality MRI. Its effectiveness and advantages
are validated by many experiments and comparisons with the related methods. 