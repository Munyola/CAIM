Segmenting aerial images is being of great potential in surveillance and scene understanding of
urban areas. It provides a mean for automatic reporting of the different events that happen in inhabited
areas. This remarkably promotes public safety and traffic management applications. After the
wide adoption of convolutional neural networks methods, the accuracy of semantic segmentation
algorithms could easily surpass 80% if a robust dataset is provided. Despite this success, the deployment
of a pre-trained segmentation model to survey a new city that is not included in the training set significantly
decreases the accuracy. This is due to the domain shift between the source dataset on which the model
is trained and the new target domain of the new city images. In this paper, we address this issue and
consider the challenge of domain adaptation in semantic segmentation of aerial images. We design
an algorithm that reduces the domain shift impact using Generative Adversarial Networks (GANs).
In the experiments, we test the proposed methodology on the International Society for Photogrammetry
and Remote Sensing (ISPRS) semantic segmentation dataset and found that our method improves the
overall accuracy from 35% to 52% when passing from Potsdam domain (considered as source domain)
to Vaihingen domain (considered as target domain). In addition, the method allows recovering efficiently
the inverted classes due to sensor variation. In particular, it improves the average segmentation
accuracy of the inverted classes due to sensor variation from 14% to 61%. 