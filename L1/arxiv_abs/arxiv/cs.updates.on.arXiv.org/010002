Typical personal medical data contains sensitive information about individuals. Storing or sharing
the personal medical data is thus often risky. For example, a short DNA sequence can provide information
that can not only identify an individual, but also his or her relatives. Nonetheless, most countries
and researchers agree on the necessity of collecting personal medical data. This stems from the
fact that medical data, including genomic data, are an indispensable resource for further research
and development regarding disease prevention and treatment. To prevent personal medical data
from being misused, techniques to reliably preserve sensitive information should be developed
for real world application. In this paper, we propose a framework called anonymized generative
adversarial networks (AnomiGAN), to improve the maintenance of privacy of personal medical data,
while also maintaining high prediction performance. We compared our method to state-of-the-art
techniques and observed that our method preserves the same level of privacy as differential privacy
(DP), but had better prediction results. We also observed that there is a trade-off between privacy
and performance results depending on the degree of preservation of the original data. Here, we provide
a mathematical overview of our proposed model and demonstrate its validation using UCI machine
learning repository datasets in order to highlight its utility in practice. Experimentally, our
approach delivers a better performance compared to that of the DP approach. 