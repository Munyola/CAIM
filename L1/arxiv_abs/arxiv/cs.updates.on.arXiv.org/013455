Visual place recognition is an important component of systems for camera localization and loop
closure detection. It concerns the recognition of a previously visited place based on visual cues
only. Although it is a widely studied problem for indoor and urban environments, the recent use of
robots for automation of agricultural and gardening tasks has created new problems, due to the challenging
appearance of garden-like environments. Garden scenes predominantly contain green colors, as
well as repetitive patterns and textures. The lack of available data recorded in gardens and natural
environments makes the improvement of visual localization algorithms difficult. In this paper
we propose an extended version of the TB-Places data set, which is designed for testing algorithms
for visual place recognition. It contains images with ground truth camera pose recorded in real
gardens in different seasons, with varying light conditions. We constructed and released a ground
truth for all possible pairs of images, indicating whether they depict the same place or not. We present
the results of a benchmark analysis of methods based on convolutional neural networks for holistic
image description and place recognition. We train existing networks (i.e. ResNet, DenseNet and
VGG NetVLAD) as backbone of a two-way architecture with a contrastive loss function. The results
that we obtained demonstrate that learning garden-tailored representations contribute to an
improvement of performance, although the generalization capabilities are limited. 