The course of surgical procedures is often unpredictable, making it difficult to estimate the duration
of procedures beforehand. This uncertainty makes scheduling surgical procedures a difficult
task. A context-aware method that analyses the workflow of an intervention online and automatically
predicts the remaining duration would alleviate these problems. As basis for such an estimate,
information regarding the current state of the intervention is a requirement. Today, the operating
room contains a diverse range of sensors. During laparoscopic interventions, the endoscopic video
stream is an ideal source of such information. Extracting quantitative information from the video
is challenging though, due to its high dimensionality. Other surgical devices (e.g. insufflator,
lights, etc.) provide data streams which are, in contrast to the video stream, more compact and easier
to quantify. Though whether such streams offer sufficient information for estimating the duration
of surgery is uncertain. In this paper, we propose and compare methods, based on convolutional neural
networks, for continuously predicting the duration of laparoscopic interventions based on unlabeled
data, such as from endoscopic image and surgical device streams. The methods are evaluated on 80
recorded laparoscopic interventions of various types, for which surgical device data and the endoscopic
video streams are available. Here the combined method performs best with an overall average error
of 37% and an average halftime error of approximately 28%. 