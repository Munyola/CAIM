360{\deg} images are usually represented in either equirectangular projection (ERP) or multiple
perspective projections. Different from the flat 2D images, the detection task is challenging
for 360{\deg} images due to the distortion of ERP and the inefficiency of perspective projections.
However, existing methods mostly focus on one of the above representations instead of both, leading
to limited detection performance. Moreover, the lack of appropriate bounding-box annotations
as well as the annotated datasets further increases the difficulties of the detection task. In this
paper, we present a standard object detection framework for 360{\deg} images. Specifically, we
adapt the terminologies of the traditional object detection task to the omnidirectional scenarios,
and propose a novel two-stage object detector, i.e., Reprojection R-CNN by combining both ERP and
perspective projection. Owing to the omnidirectional field-of-view of ERP, Reprojection R-CNN
first generates coarse region proposals efficiently by a distortion-aware spherical region proposal
network. Then, it leverages the distortion-free perspective projection and refines the proposed
regions by a novel reprojection network. We construct two novel synthetic datasets for training
and evaluation. Experiments reveal that Reprojection R-CNN outperforms the previous state-of-the-art
methods on the mAP metric. In addition, the proposed detector could run at 178ms per image in the panoramic
datasets, which implies its practicability in real-world applications. 