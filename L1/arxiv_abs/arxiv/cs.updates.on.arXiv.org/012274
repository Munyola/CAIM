The Internet and, in particular, Online Social Networks have changed the way that terrorist and
extremist groups can influence and radicalise individuals. Recent reports show that the mode of
operation of these groups starts by exposing a wide audience to extremist material online, before
migrating them to less open online platforms for further radicalization. Thus, identifying radical
content online is crucial to limit the reach and spread of the extremist narrative. In this paper,
our aim is to identify measures to automatically detect radical content in social media. We identify
several signals, including textual, psychological and behavioural, that together allow for the
classification of radical messages. Our contribution is three-fold: (1) we analyze propaganda
material published by extremist groups and create a contextual text-based model of radical content,
(2) we build a model of psychological properties inferred from these material, and (3) we evaluate
these models on Twitter to determine the extent to which it is possible to automatically identify
online radical tweets. Our results show that radical users do exhibit distinguishable textual,
psychological, and behavioural properties. We find that the psychological properties are among
the most distinguishing features. Additionally, our results show that textual models using vector
embedding features significantly improves the detection over TF-IDF features. We validate our
approach on two experiments achieving high accuracy. Our findings can be utilized as signals for
detecting online radicalization activities. 