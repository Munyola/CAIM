Current upper extremity outcome measures for persons with cervical spinal cord injury (cSCI) lack
the ability to directly collect quantitative information in home and community environments.
A wearable first-person (egocentric) camera system is presented that can monitor functional hand
use outside of clinical settings. The system is based on computer vision algorithms that detect
the hand, segment the hand outline, distinguish the user's left or right hand, and detect functional
interactions of the hand with objects during activities of daily living. The algorithm was evaluated
using egocentric video recordings from 9 participants with cSCI, obtained in a home simulation
laboratory. The system produces a binary hand-object interaction decision for each video frame,
based on features reflecting motion cues of the hand, hand shape and colour characteristics of the
scene. This output was compared with a manual labelling of the video, yielding F1-scores of 0.74
$\pm$ 0.15 for the left hand and 0.73 $\pm$ 0.15 for the right hand. From the resulting frame-by-frame
binary data, functional hand use measures were extracted: the amount of total interaction as a percentage
of testing time, the average duration of interactions in seconds, and the number of interactions
per hour. Moderate and significant correlations were found when comparing these output measures
to the results of the manual labelling, with $\rho$ = 0.40, 0.54 and 0.55 respectively. These results
demonstrate the potential of a wearable egocentric camera for capturing quantitative measures
of hand use at home. 