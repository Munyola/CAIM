We present a novel approach to detect synthetic content in portrait videos, as a preventive solution
for the emerging threat of deep fakes. In other words, we introduce a deep fake detector. We observe
that detectors blindly utilizing deep learning are not effective in catching fake content, as generative
models produce formidably realistic results. Our key assertion follows that biological signals
hidden in portrait videos can be used as an implicit descriptor of authenticity, because they are
neither spatially nor temporally preserved in fake content. To prove and exploit this assertion,
we first exhibit several unary and binary signal transformations for the pairwise separation problem,
achieving 99.39% accuracy. Second, we utilize those findings to formulate a generalized classifier
for fake content, by analyzing proposed signal transformations and corresponding feature sets.
Third, we generate novel signal maps and employ a CNN to improve our traditional classifier for detecting
synthetic content. Lastly, we release an "in the wild" dataset of fake portrait videos that we collected
as a part of our evaluation process. We evaluate FakeCatcher both on Face Forensics dataset and on
our new Deep Fakes dataset, performing with 96% and 91.07% accuracies respectively. In addition,
our approach produces a significantly superior detection rate against baselines, and does not
depend on the source, generator, or properties of the fake content. We also analyze signals from
various facial regions, with varying segment durations, and under several dimensionality reduction
techniques. 