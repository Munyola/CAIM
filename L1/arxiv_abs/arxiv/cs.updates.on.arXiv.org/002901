This paper presents a method of learning qualitatively interpretable models in object detection
using popular two-stage region-based ConvNet detection systems (i.e., R-CNN). R-CNN consists
of a region proposal network and a RoI (Region-of-Interest) prediction network.By interpretable
models, we focus on weakly-supervised extractive rationale generation, that is learning to unfold
latent discriminative part configurations of object instances automatically and simultaneously
in detection without using any supervision for part configurations. We utilize a top-down hierarchical
and compositional grammar model embedded in a directed acyclic AND-OR Graph (AOG) to explore and
unfold the space of latent part configurations of RoIs. We propose an AOGParsing operator to substitute
the RoIPooling operator widely used in R-CNN, so the proposed method is applicable to many state-of-the-art
ConvNet based detection systems. The AOGParsing operator aims to harness both the explainable
rigor of top-down hierarchical and compositional grammar models and the discriminative power
of bottom-up deep neural networks through end-to-end training. In detection, a bounding box is
interpreted by the best parse tree derived from the AOG on-the-fly, which is treated as the extractive
rationale generated for interpreting detection. In learning, we propose a folding-unfolding
method to train the AOG and ConvNet end-to-end. In experiments, we build on top of the R-FCN and test
the proposed method on the PASCAL VOC 2007 and 2012 datasets with performance comparable to state-of-the-art
methods. 