An important goal of research in Deep Reinforcement Learning in mobile robotics is to train agents
capable of solving complex tasks, which require a high level of scene understanding and reasoning
from an egocentric perspective. When trained from simulations, optimal environments should satisfy
a currently unobtainable combination of high-fidelity photographic observations, massive amounts
of different environment configurations and fast simulation speeds. In this paper we argue that
research on training agents capable of complex reasoning can be simplified by decoupling from the
requirement of high fidelity photographic observations. We present a suite of tasks requiring
complex reasoning and exploration in continuous, partially observable 3D environments. The objective
is to provide challenging scenarios and a robust baseline agent architecture that can be trained
on mid-range consumer hardware in under 24h. Our scenarios combine two key advantages: (i) they
are based on a simple but highly efficient 3D environment (ViZDoom) which allows high speed simulation
(12000fps); (ii) the scenarios provide the user with a range of difficulty settings, in order to
identify the limitations of current state of the art algorithms and network architectures. We aim
to increase accessibility to the field of Deep-RL by providing baselines for challenging scenarios
where new ideas can be iterated on quickly. We argue that the community should be able to address challenging
problems in reasoning of mobile agents without the need for a large compute infrastructure. 