Actual causation is concerned with the question "what caused what?" Consider a transition between
two states within a system of interacting elements, such as an artificial neural network, or a biological
brain circuit. Which combination of synapses caused the neuron to fire? Which image features caused
the classifier to misinterpret the picture? Even detailed knowledge of the system's causal network,
its elements, their states, connectivity, and dynamics does not automatically provide a straightforward
answer to the "what caused what?" question. Counterfactual accounts of actual causation based
on graphical models, paired with system interventions, have demonstrated initial success in addressing
specific problem cases in line with intuitive causal judgments. Here, we start from a set of basic
requirements for causation (realization, composition, information, integration, and exclusion)
and develop a rigorous, quantitative account of actual causation that is generally applicable
to discrete dynamical systems. We present a formal framework to evaluate these causal requirements
that is based on system interventions and partitions, and considers all counterfactuals of a state
transition. This framework is used to provide a complete causal account of the transition by identifying
and quantifying the strength of all actual causes and effects linking the two consecutive system
states. Finally, we examine several exemplary cases and paradoxes of causation and show that they
can be illuminated by the proposed framework for quantifying actual causation. 