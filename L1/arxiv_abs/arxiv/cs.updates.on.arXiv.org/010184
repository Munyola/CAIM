Generating eye diagrams by using a circuit simulator can be very computationally intensive, especially
in the presence of nonlinearities. It often involves multiple Newton-like iterations at every
time step when a SPICE-like circuit simulator handles a nonlinear system in the transient regime.
In this paper, we leverage machine learning methods, to be specific, the recurrent neural network
(RNN), to generate black-box macromodels and achieve significant reduction of computation time.
Through the proposed approach, an RNN model is first trained and then validated on a relatively short
sequence generated from a circuit simulator. Once the training completes, the RNN can be used to
make predictions on the remaining sequence in order to generate an eye diagram. The training cost
can also be amortized when the trained RNN starts making predictions. Besides, the proposed approach
requires no complex circuit simulations nor substantial domain knowledge. We use two high-speed
link examples to demonstrate that the proposed approach provides adequate accuracy while the computation
time can be dramatically reduced. In the high-speed link example with a PAM4 driver, the eye diagram
generated by RNN models shows good agreement with that obtained from a commercial circuit simulator.
This paper also investigates the impacts of various RNN topologies, training schemes, and tunable
parameters on both the accuracy and the generalization capability of an RNN model. It is found out
that the long short-term memory (LSTM) network outperforms the vanilla RNN in terms of the accuracy
in predicting transient waveforms. 