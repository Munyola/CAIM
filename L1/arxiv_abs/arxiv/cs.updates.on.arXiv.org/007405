Mesh subdivision is a key geometric modeling task which forges smooth, supple, eye-pleasing surfaces
out of coarse polygonal outlines. Since its rise to mainstream around the turn of the century, subdivision
has become an unavoidable production tool. With industrial demands in sight, there has been a steady
effort for developing faster and more efficient subdivision implementations. Despite the tremendous
parallelism potential of subdivision algorithms, state-of-the-art implementations are only
partially parallel as they are riddled by intermediate serial steps and therefore fail to unleash
the compute power of massively parallel devices such as graphics processing units (GPUs). To fully
parallelize the subdivision process, we discard traditional linked list data structures in favor
of a sparse matrix linear algebra formalism. Subdivision algorithms are written in the language
of linear algebra with customized operators which readily demonstrate a performance edge over
existing approaches. To further increase performance, we automatically identify critical matrix
operations and replace them by specialized, heavily tuned GPU kernels. To substantiate the versatility
of our approach we apply it to $\sqrt{3}$, Loop and Catmull-Clark subdivision schemes and show support
for adaptive subdivision, semi-sharp creases, and a split evaluation scheme that separates topology
and topological changes from positional updates. Our results indicate substantial performance
gains over the state-of-the-art and current industry standard. 