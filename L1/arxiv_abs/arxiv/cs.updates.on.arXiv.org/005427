For distributed computing environments, we consider the canonical machine learning problem of
empirical risk minimization (ERM) with quadratic regularization, and we propose a distributed
and communication-efficient Newton-type optimization method. At every iteration, each worker
locally finds an Approximate NewTon (ANT) direction, and then it sends this direction to the main
driver. The driver, then, averages all the ANT directions received from workers to form a Globally
Improved ANT (GIANT) direction. GIANT naturally exploits the trade-offs between local computations
and global communications in that more local computations result in fewer overall rounds of communications.
GIANT is highly communication efficient in that, for $d$-dimensional data uniformly distributed
across $m$ workers, it has $4$ or $6$ rounds of communication and $O (d \log m)$ communication complexity
per iteration. Theoretically, we show that GIANT's convergence rate is faster than first-order
methods and existing distributed Newton-type methods. From a practical point-of-view, a highly
beneficial feature of GIANT is that it has only one tuning parameter---the iterations of the local
solver for computing an ANT direction. This is indeed in sharp contrast with many existing distributed
Newton-type methods, as well as popular first-order methods, which have several tuning parameters,
and whose performance can be greatly affected by the specific choices of such parameters. In this
light, we empirically demonstrate the superior performance of GIANT compared with other competing
methods. 