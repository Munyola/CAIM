As an important format of multimedia, music has filled almost everyone's life. Automatic analyzing
music is a significant step to satisfy people's need for music retrieval and music recommendation
in an effortless way. Thereinto, downbeat tracking has been a fundamental and continuous problem
in Music Information Retrieval (MIR) area. Despite significant research efforts, downbeat tracking
still remains a challenge. Previous researches either focus on feature engineering (extracting
certain features by signal processing, which are semi-automatic solutions); or have some limitations:
they can only model music audio recordings within limited time signatures and tempo ranges. Recently,
deep learning has surpassed traditional machine learning methods and has become the primary algorithm
in feature learning; the combination of traditional and deep learning methods also has made better
performance. In this paper, we begin with a background introduction of downbeat tracking problem.
Then, we give detailed discussions of the following topics: system architecture, feature extraction,
deep neural network algorithms, datasets, and evaluation strategy. In addition, we take a look
at the results from the annual benchmark evaluation--Music Information Retrieval Evaluation
eXchange (MIREX)--as well as the developments in software implementations. Although much has
been achieved in the area of automatic downbeat tracking, some problems still remain. We point out
these problems and conclude with possible directions and challenges for future research. 