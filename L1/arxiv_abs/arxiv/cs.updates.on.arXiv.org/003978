This paper presents a novel framework for demystification of convolutional deep learning models
for time series analysis. This is a step towards making informed/explainable decisions in the domain
of time series, powered by deep learning. There have been numerous efforts to increase the interpretability
of image-centric deep neural network models, where the learned features are more intuitive to visualize.
Visualization in time-series is much more complicated as there is no direct interpretation of the
filters and inputs as compared to image modality. In addition, little or no concentration has been
devoted for the development of such tools in the domain of time-series in the past. The visualization
engine of the presented framework provides possibilities to explore and analyze a network from
different dimensions at four different levels of abstraction. This enables the user to uncover
different aspects of the model which includes important filters, filter clusters, and input saliency
maps. These representations allow to understand the network features so that the acceptability
of deep networks for time-series data can be enhanced. This is extremely important in domains like
finance, industry 4.0, self-driving cars, health-care, counter-terrorism etc., where reasons
for reaching a particular prediction are equally important as the prediction itself. The framework
\footnote{Framework download link: https://hidden.for.blind.review} can also aid in discovery
of the filters which are contributing nothing to the final prediction, hence, can be pruned without
any significant loss in performance. 