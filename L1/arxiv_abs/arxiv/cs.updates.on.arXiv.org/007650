We combine two recent lines of research on sublinear clustering to significantly increase the efficiency
of training Gaussian mixture models (GMMs) on large scale problems. First, we use a novel truncated
variational EM approach for GMMs with isotropic Gaussians in order to increase clustering efficiency
for large $C$ (many clusters). Second, we use recent coreset approaches to increase clustering
efficiency for large $N$ (many data points). In order to derive a novel accelerated algorithm, we
first show analytically how variational EM and coreset objectives can be merged to give rise to a
new, combined clustering objective. Each iteration of the novel algorithm derived from this merged
objective is then shown to have a run-time cost of $\mathcal{O}(N' G^2 D)$ per iteration, where $N'<N$
is the coreset size and $G^2<C$ is a constant related to the extent of local cluster neighborhoods.
While enabling clustering with a strongly reduced number of distance evaluations per iteration,
the combined approach is observed to still very effectively increase the clustering objective.
In a series of numerical experiments on standard benchmarks, we use efficient seeding for initialization
and evaluate the net computational demand of the merged approach in comparison to (already highly
efficient) recent approaches. As result, depending on the dataset and number of clusters, the merged
algorithm shows several times (and up to an order of magnitude) faster execution times to reach the
same quantization errors as algorithms based on coresets or on variational EM alone. 