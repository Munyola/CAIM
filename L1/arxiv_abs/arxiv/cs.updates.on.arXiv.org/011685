We address the multi-focus image fusion problem, where multiple images captured with different
focal settings are to be fused into an all-in-focus image of higher quality. Algorithms for this
problem necessarily admit the source image characteristics along with focused and blurred features.
However, most sparsity-based approaches use a single dictionary in focused feature space to describe
multi-focus images, and ignore the representations in blurred feature space. We propose a multi-focus
image fusion approach based on sparse representation using a coupled dictionary. It exploits the
observations that the patches from a given training set can be sparsely represented by a couple of
overcomplete dictionaries related to the focused and blurred categories of images and that a sparse
approximation based on such coupled dictionary leads to a more flexible and therefore better fusion
strategy than the one based on just selecting the sparsest representation in the original image
estimate. In addition, to improve the fusion performance, we employ a coupled dictionary learning
approach that enforces pairwise correlation between atoms of dictionaries learned to represent
the focused and blurred feature spaces. We also discuss the advantages of the fusion approach based
on coupled dictionary learning, and present efficient algorithms for fusion based on coupled dictionary
learning. Extensive experimental comparisons with state-of-the-art multi-focus image fusion
algorithms validate the effectiveness of the proposed approach. 