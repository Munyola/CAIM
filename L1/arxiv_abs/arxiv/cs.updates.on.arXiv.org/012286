Vision-based navigation of autonomous vehicles primarily depends on the Deep Neural Network (DNN)
based systems in which the controller obtains input from sensors/detectors, such as cameras and
produces a vehicle control output, such as a steering wheel angle to navigate the vehicle safely
in a roadway traffic environment. Typically, these DNN-based systems of the autonomous vehicle
are trained through supervised learning; however, recent studies show that a trained DNN-based
system can be compromised by perturbation or adversarial inputs. Similarly, this perturbation
can be introduced into the DNN-based systems of autonomous vehicle by unexpected roadway hazards,
such as debris and roadblocks. In this study, we first introduce a roadway hazardous environment
(both intentional and unintentional roadway hazards) that can compromise the DNN-based navigational
system of an autonomous vehicle, and produces an incorrect steering wheel angle, which can cause
crashes resulting in fatality and injury. Then, we develop a DNN-based autonomous vehicle driving
system using object detection and semantic segmentation to mitigate the adverse effect of this
type of hazardous environment, which helps the autonomous vehicle to navigate safely around such
hazards. We find that our developed DNN-based autonomous vehicle driving system including hazardous
object detection and semantic segmentation improves the navigational ability of an autonomous
vehicle to avoid a potential hazard by 21% compared to the traditional DNN-based autonomous vehicle
driving system. 