OBJECTIVE: We aim to extract and denoise the attended speaker in a noisy, two-speaker acoustic scenario,
relying on microphone array recordings from a binaural hearing aid, which are complemented with
electroencephalography (EEG) recordings to infer the speaker of interest. METHODS: In this study,
we propose a modular processing flow that first extracts the two speech envelopes from the microphone
recordings, then selects the attended speech envelope based on the EEG, and finally uses this envelope
to inform a multi-channel speech separation and denoising algorithm. RESULTS: Strong suppression
of interfering (unattended) speech and background noise is achieved, while the attended speech
is preserved. Furthermore, EEG-based auditory attention detection (AAD) is shown to be robust
to the use of noisy speech signals. CONCLUSIONS: Our results show that AAD-based speaker extraction
from microphone array recordings is feasible and robust, even in noisy acoustic environments,
and without access to the clean speech signals to perform EEG-based AAD. SIGNIFICANCE: Current
research on AAD always assumes the availability of the clean speech signals, which limits the applicability
in real settings. We have extended this research to detect the attended speaker even when only microphone
recordings with noisy speech mixtures are available. This is an enabling ingredient for new brain-computer
interfaces and effective filtering schemes in neuro-steered hearing prostheses. Here, we provide
a first proof of concept for EEG-informed attended speaker extraction and denoising. 