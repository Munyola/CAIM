Legged robots can outperform wheeled machines for most navigation tasks across unknown and rough
terrains. For such tasks, visual feedback is a fundamental asset to provide robots with terrain-awareness.
However, robust dynamic locomotion on difficult terrains with real-time performance guarantees
remains a challenge. Indeed, the computational effort demanded by visual processing limits the
potential for realtime control and planning strategies. In this paper, we present a real-time,
dynamic foothold adaptation strategy based on visual feedback. Our method adjusts the landing
position of the feet in a fully reactive manner, using only on-board computers and sensors. The correction
is computed and executed continuously along the swing phase trajectory of each leg. To efficiently
adapt the landing position, we implement a self-supervised foothold classifier based on a Convolutional
Neural Network (CNN). The training set is automatically generated by a heuristic algorithm that
jointly evaluates terrain morphology, kinematics, and leg collisions. Our method results in an
up to 200 times faster computation with respect to the full-blown heuristics. Our goal is to react
to visual stimuli from the environment, bridging the gap between blind reactive locomotion and
purely vision-based planning strategies. We assess the performance of our method on the dynamic
quadruped robot HyQ, executing static and dynamic gaits (at speeds up to 0.5 m/s) in both simulated
and real scenarios; the benefit of safe foothold adaptation is clearly demonstrated by the overall
robot behavior. 