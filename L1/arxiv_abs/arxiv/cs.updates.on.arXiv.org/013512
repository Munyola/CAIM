We present a real-time approach for multi-person 3D motion capture at over 30 fps using a single RGB
camera. It operates in generic scenes and is robust to difficult occlusions both by other people
and objects. Our method operates in subsequent stages. The first stage is a convolutional neural
network (CNN) that estimates 2D and 3D pose features along with identity assignments for all visible
joints of all individuals. We contribute a new architecture for this CNN, called SelecSLS Net, that
uses novel selective long and short range skip connections to improve the information flow allowing
for a drastically faster network without compromising accuracy. In the second stage, a fully-connected
neural network turns the possibly partial (on account of occlusion) 2D pose and 3D pose features
for each subject into a complete 3D pose estimate per individual. The third stage applies space-time
skeletal model fitting to the predicted 2D and 3D pose per subject to further reconcile the 2D and
3D pose, and enforce temporal coherence. Our method returns the full skeletal pose in joint angles
for each subject. This is a further key distinction from previous work that neither extracted global
body positions nor joint angle results of a coherent skeleton in real time for multi-person scenes.
The proposed system runs on consumer hardware at a previously unseen speed of more than 30 fps given
512x320 images as input while achieving state-of-the-art accuracy, which we will demonstrate
on a range of challenging real-world scenes. 