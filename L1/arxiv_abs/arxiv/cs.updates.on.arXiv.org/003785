Face recognition has achieved revolutionary advancement owing to the advancement of the deep convolutional
neural network (CNN). The central task of face recognition, including face verification and identification,
involves face feature discrimination. However, traditional softmax loss of deep CNN usually lacks
the power of discrimination. To address this problem, recently several loss functions such as central
loss \cite{centerloss}, large margin softmax loss \cite{lsoftmax}, and angular softmax loss
\cite{sphereface} have been proposed. All these improvement algorithms share the same idea: maximizing
inter-class variance and minimizing intra-class variance. In this paper, we design a novel loss
function, namely large margin cosine loss (LMCL), to realize this idea from a different perspective.
More specifically, we reformulate the softmax loss as cosine loss by L2 normalizing both features
and weight vectors to remove radial variation, based on which a cosine margin term \emph{$m$} is
introduced to further maximize decision margin in angular space. As a result, minimum intra-class
variance and maximum inter-class variance are achieved by normalization and cosine decision margin
maximization. We refer to our model trained with LMCL as CosFace. To test our approach, extensive
experimental evaluations are conducted on the most popular public-domain face recognition datasets
such as MegaFace Challenge, Youtube Faces (YTF) and Labeled Face in the Wild (LFW). We achieve the
state-of-the-art performance on these benchmark experiments, which confirms the effectiveness
of our approach. 