More than 80% of today's data is unstructured in nature, and these unstructured datasets evolve
over time. A large part of these datasets are text documents generated by media outlets, scholarly
articles in digital libraries, findings from scientific and professional communities, and social
media. Vector space models were developed to analyze text data using data mining and machine learning
algorithms. While ample vector space models exist for text data, the evolutionary aspect of ever-changing
text corpora is still missing in vector-based representations. The advent of word embeddings has
enabled us to create a contextual vector space, but the embeddings fail to consider the temporal
aspects of the feature space successfully. This paper presents an approach to include temporal
aspects in feature spaces. The inclusion of the time aspect in the feature space provides vectors
for every natural language element, such as words or entities, at every timestamp. Such temporal
word vectors allow us to track how the meaning of a word changes over time, by studying the changes
in its neighborhood. Moreover, a time-reflective text representation will pave the way to a new
set of text analytic abilities involving time series for text collections. In this paper, we present
a time-reflective vector space model for temporal text data that is able to capture short and long-term
changes in the meaning of words. We compare our approach with the limited literature on dynamic embeddings.
We present qualitative and quantitative evaluations using the tracking of semantic evolution
as the target application. 