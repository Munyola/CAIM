Researches have shown that diet recording can help people increase awareness of food intake and
improve nutrition management, and thereby maintain a healthier life. Recently, researchers have
been working on smartphone-based diet recording methods and applications that help users accomplish
two tasks: record what they eat and how much they eat. Although the former task has made great progress
through adopting image recognition technology, it is still a challenge to estimate the volume of
foods accurately and conveniently. In this paper, we propose a novel method, named MUSEFood, for
food volume estimation. MUSEFood uses the camera to capture photos of the food, but unlike existing
volume measurement methods, MUSEFood requires neither training images with volume information
nor placing a reference object of known size while taking photos. In addition, considering the impact
of different containers on the contour shape of foods, MUSEFood uses a multi-task learning framework
to improve the accuracy of food segmentation, and uses a differential model applicable for various
containers to further reduce the negative impact of container differences on volume estimation
accuracy. Furthermore, MUSEFood uses the microphone and the speaker to accurately measure the
vertical distance from the camera to the food in a noisy environment, thus scaling the size of food
in the image to its actual size. The experiments on real foods indicate that MUSEFood outperforms
state-of-the-art approaches, and highly improves the speed of food volume estimation. 