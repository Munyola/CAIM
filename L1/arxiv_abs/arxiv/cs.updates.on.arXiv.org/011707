Knowledge graphs (KGs), i.e. representation of information as a semantic graph, provide a significant
test bed for many tasks including question answering, recommendation, and link prediction. Various
amount of scholarly metadata have been made vailable as knowledge graphs from the diversity of data
providers and agents. However, these high-quantities of data remain far from quality criteria
in terms of completeness while growing at a rapid pace. Most of the attempts in completing such KGs
are following traditional data digitization, harvesting and collaborative curation approaches.
Whereas, advanced AI-related approaches such as embedding models - specifically designed for
such tasks - are usually evaluated for standard benchmarks such as Freebase and Wordnet. The tailored
nature of such datasets prevents those approaches to shed the lights on more accurate discoveries.
Application of such models on domain-specific KGs takes advantage of enriched meta-data and provides
accurate results where the underlying domain can enormously benefit. In this work, the TransE embedding
model is reconciled for a specific link prediction task on scholarly metadata. The results show
a significant shift in the accuracy and performance evaluation of the model on a dataset with scholarly
metadata. The newly proposed version of TransE obtains 99.9% for link prediction task while original
TransE gets 95%. In terms of accuracy and Hit@10, TransE outperforms other embedding models such
as ComplEx, TransH and TransR experimented over scholarly knowledge graphs 