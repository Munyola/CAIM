The ability of a researcher to re-identify (re-ID) an animal individual upon re-encounter is fundamental
for addressing a broad range of questions in the study of ecosystem function, community and population
dynamics, and behavioural ecology. Tagging animals during mark and recapture studies is the most
common method for reliable animal re-ID however camera traps are a desirable alternative, requiring
less labour, much less intrusion, and prolonged and continuous monitoring into an environment.
Despite these advantages, the analyses of camera traps and video for re-ID by humans are criticized
for their biases related to human judgment and inconsistencies between analyses. Recent years
have witnessed the emergence of deep learning systems which re-ID humans based on image and video
data with near perfect accuracy. Despite this success, there are limited examples of this approach
for animal re-ID. Here, we demonstrate the viability of novel deep similarity learning methods
on five species: humans, chimpanzees, humpback whales, octopus and fruit flies. Our implementation
demonstrates the generality of this framework as the same process provides accurate results beyond
the capabilities of a human observer. In combination with a species object detection model, this
methodology will allow ecologists with camera/video trap data to re-identify individuals that
exit and re-enter the camera frame. Our expectation is that this is just the beginning of a major trend
that could stand to revolutionize the analysis of camera trap data and, ultimately, our approach
to animal ecology. 